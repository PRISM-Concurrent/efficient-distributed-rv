#+TITLE: API Usage Guide - Efficient Distributed Runtime Verification
#+AUTHOR: Efficient Distributed RV Project
#+DATE: December 2025
#+OPTIONS: toc:2 num:t

* Overview

This document is a *developer-facing* API guide for the Efficient Distributed
Runtime Verification framework.

The framework offers two complementary ways to run a verification:

1. *Low-level workflow* via =Executioner=
   (explicit execution and verification phases).
2. *High-level fluent API* via =VerificationFramework=
   (recommended for most users).

Terminology used throughout this document:

- *Implementation under inspection*:
  the concurrent object being tested
  (e.g., =ConcurrentLinkedQueue=).
- *Object type*:
  logical label selecting the sequential specification
  (e.g., ="queue"=, ="map"=).
- *Snapshot strategy*:
  instrumentation mechanism used to obtain the execution
  (e.g., ="gAIsnap"= or ="rawsnap"=).
- *Workload*:
  strategy used to generate operations
  (random, pattern-based, or explicit).
- *Schedule*:
  a fixed list of operations (=OperationCall=) *without thread IDs*;
  thread assignment is performed by the execution layer.

* Core Concepts

This section explains the conceptual and algorithmic foundations of the
framework.  It is intended for developers who want to understand how
executions are collected and how linearizability is checked.

** Runtime Verification Architecture

The framework follows the classical three-layer architecture of runtime
verification:

1. *Instrumentation* – obtain the current concurrent execution.
2. *Monitoring* – decide whether the execution satisfies the property.
3. *Specification* – define correct sequential behavior.

This guide focuses on the *instrumentation* and *monitoring* layers for
linearizability.

[[file:systemArquitecture.svg]]

** Instrumentation: Wrappers (Happens-before detection objects)

A *wrapper* is a distributed instrumentation mechanism that intercepts
method calls on the implementation under inspection in order to construct
a partial order of operations using shared memory.

Each operation execution follows three conceptual steps:

1. The invocation is written into a shared snapshot object.
2. The operation is applied to the concrete implementation to obtain a response.
3. The response and observed invocations are written back to the snapshot.

The snapshot does *not* need to be linearizable.  It is sufficient that it
captures enough ordering information to detect violations.

If the execution collected by the wrapper is not linearizable, then the
implementation under inspection is also not linearizable.  This property
is known as *predictive soundness*.

This approach was introduced by Castañeda and Rodríguez (PODC 2023).

** Snapshot Strategies

The framework uses *non-linearizable snapshot objects* based on a
decoupled collect mechanism, shown to be sufficient for runtime
verification of linearizability (Rodríguez & Castañeda, RV 2024).

Two snapshot strategies are provided.

*** GAI (Get-And-Increment)

- Uses an atomic fetch-and-increment operation to order events.
- Provides a total order over collected events.
- Has low overhead, making it suitable for lightweight instrumentation.

*** RAW (Read-After-Write)

- Uses a read-after-write mechanism to order events.
- Returns pointers to immutable vectors (Clojure persistent data structures).
- Captures happens-before relationships between events.
- Provides more precise causality information than GAI.

** Specification: Linearizability

A concurrent execution is *linearizable* if:

1. Each operation appears to take effect atomically at some point between
   its invocation and its response.
2. The real-time order of non-overlapping operations is preserved.
3. The resulting sequential execution satisfies the sequential specification.

The framework checks linearizability with respect to a sequential
specification determined by the selected *object type* (e.g., queue, set,
map).

** JIT-based Linearizability Checking

The monitoring component checks whether a collected concurrent history is
linearizable with respect to the chosen sequential specification.

The checker is based on the *Just-In-Time* tree search algorithm for
linearizability testing proposed by Lowe (2017), adapted to a functional
setting in Clojure.

Key properties:

- Works incrementally and supports partial histories, including pending operations.
- Uses a backtrackable sequential specification.
- Sequential states are immutable, so backtracking is achieved by reusing
  previous states rather than explicitly undoing operations.


* High-Level API: VerificationFramework

** Entry points: =verify(...)=

=VerificationFramework= provides three factory methods that return a
=VerificationBuilder=.

*** =verify(Class<?> algorithmClass)=

Use this variant when the implementation is available as a Java class.

*** =verify(String className)=

Use this variant when only a fully-qualified class name is available.
The class is loaded via reflection.

Throws =IllegalArgumentException= if the class cannot be found.

*** =verify(Object instance)=

Use this variant when you already have an object instance.

*Important:* the current implementation uses =instance.getClass()= only;
the provided instance itself is not executed.

** Minimal example (recommended)

#+BEGIN_SRC java
import phd.distributed.api.VerificationFramework;
import phd.distributed.api.VerificationResult;

import java.util.concurrent.ConcurrentLinkedQueue;

public class MinimalVerifyDemo {
  public static void main(String[] args) {
    VerificationResult result = VerificationFramework
        .verify(ConcurrentLinkedQueue.class)
        .withThreads(4)
        .withOperations(100)
        .withObjectType("queue")
        .withMethods("offer", "poll")
        .withSnapshot("gAIsnap")
        .run();

    System.out.println("Linearizable: " + result.isLinearizable());
    System.out.println("Total time: "
        + result.getExecutionTime().toMillis() + " ms");
  }
}
#+END_SRC

* Builder configuration

** Concurrency and execution parameters

*** =withThreads(int threads)=

Sets the number of concurrent worker threads that invoke operations.

- Typical values: 2–16.
- Higher values increase interleavings but may increase overhead.

*** =withOperations(int operations)=

Sets the total number of operations executed *across all threads*.

*** =withTimeout(Duration timeout)=

Sets the maximum allowed time for =run()=.
Internally, =run()= waits for =runAsync()= using this timeout.

Example:
#+BEGIN_SRC java
.withTimeout(java.time.Duration.ofSeconds(30))
#+END_SRC

If the timeout expires, =run()= throws a runtime exception.

** Object and method configuration

*** =withObjectType(String type)=

Selects the sequential specification and the read/write classification.

Supported object types and expected method names:

- ="queue"=
  - write: =offer, add, put=
  - read:  =poll, peek=
- ="deque"=
  - write: =offerFirst, offerLast, addFirst, addLast=
  - read:  =pollFirst, pollLast, peekFirst, peekLast=
- ="set"=
  - write: =add, remove=
  - read:  =contains=
- ="map"=
  - write: =put, remove=
  - read:  =get, containsKey, containsValue=

*** =withMethods(String... methods)=

Restricts the set of methods that can be invoked during execution.

This is *strongly recommended* for:
- reproducibility,
- meaningful workloads,
- avoiding irrelevant API methods.

Example:
#+BEGIN_SRC java
.withMethods("offer", "poll")
#+END_SRC

** Snapshot strategy

*** =withSnapshot(String snapType)=

Selects the instrumentation strategy used to collect the execution.

Supported identifiers (case-insensitive):

- ="gAIsnap"= → CollectFAInc
  - Total order of events
  - Fetch-and-increment based
  - Low overhead
- ="rawsnap"= → CollectRAW
  - Read-after-write ordering
  - Captures happens-before relations
  - More precise causality

Example:
#+BEGIN_SRC java
.withSnapshot("rawsnap")
#+END_SRC

If an unknown value is provided, the system falls back to GAI.

* Workload control

The framework supports three ways to generate operations:

1) Default internal random selection.
2) A =WorkloadPattern= (controlled read/write distribution).
3) An explicit schedule (=List<OperationCall>=).

A workload controls *which operations* are generated, but *not* which
thread executes them. Thread assignment is handled by the execution layer
(=Executioner=).

** =withWorkload(WorkloadPattern pattern)=

Attaches a workload generator that produces a list of =OperationCall= objects.

Properties:

- Exactly =operations= calls are generated.
- Each call is a method invocation (=MethodInf= + arguments).
- *No thread IDs are assigned.*
- Read vs write choice is workload-dependent.
- Concrete methods depend on =objectType= and method name.

The resulting list is executed using =taskProducersSeed(...)=.

** How =WorkloadPattern= generates operations

For each operation index *i*, the pattern decides:

1) Whether the operation is a *write* or a *read*.
2) Which method name matches that category for the given =objectType=.
3) Which arguments are generated
   (via =OperationCall.fromMethod(...)=).

The =threads= parameter stored in =WorkloadPattern= is currently kept for
convenience/documentation; it does *not* assign thread IDs.

** Method classification by object type

| Object type | Write methods                            | Read methods                               |
|-------------+------------------------------------------+--------------------------------------------|
| queue       | offer, add, put                          | poll, peek                                |
| deque       | offerFirst, offerLast, addFirst, addLast | pollFirst, pollLast, peekFirst, peekLast  |
| set         | add, remove                              | contains                                  |
| map         | put, remove                              | get, containsKey, containsValue           |

If =withMethods(...)= is used, only that subset is considered.
Otherwise, methods are discovered via reflection and then filtered
by this classification.

** Workload patterns

*** UNIFORM

Factory:
- =WorkloadPattern.uniform(operations, threads)=

Behavior:
- 50% write, 50% read.
- Methods chosen uniformly from the corresponding sets.

*** PRODUCER–CONSUMER

Factory:
- =WorkloadPattern.producerConsumer(operations, threads, producerRatio)=

Behavior:
- With probability =producerRatio=: write
- With probability =1 - producerRatio=: read

Models enqueue/dequeue or put/get workloads.

*** READ-HEAVY

Factory:
- =WorkloadPattern.readHeavy(operations, threads, readRatio)=

Behavior:
- Mostly reads
- Writes with probability =1 - readRatio=

*** WRITE-HEAVY

Factory:
- =WorkloadPattern.writeHeavy(operations, threads, writeRatio)=

Behavior:
- Mostly writes
- Reads with probability =1 - writeRatio=

** Example: producer–consumer queue workload

#+BEGIN_SRC java
import phd.distributed.api.VerificationFramework;
import phd.distributed.api.VerificationResult;
import phd.distributed.api.WorkloadPattern;
import java.util.concurrent.ConcurrentLinkedQueue;

public class WorkloadQueueDemo {
  public static void main(String[] args) {
    WorkloadPattern pattern =
        WorkloadPattern.producerConsumer(100, 4, 0.7);

    VerificationResult result = VerificationFramework
        .verify(ConcurrentLinkedQueue.class)
        .withThreads(4)
        .withOperations(100)
        .withObjectType("queue")
        .withMethods("offer", "poll")
        .withSnapshot("gAIsnap")
        .withWorkload(pattern)
        .run();

    System.out.println("Linearizable: " + result.isLinearizable());
  }
}
#+END_SRC

** Explicit schedules

*** =withSchedule(List<OperationCall> schedule)=

Uses a fixed, deterministic sequence of operations.

Useful for:
- debugging,
- reproducing failures,
- publishing minimal counterexamples.

#+BEGIN_SRC java
// Fixed schedule example omitted for brevity; see User Manual
#+END_SRC

* Low-Level API: Executioner + DistAlgorithm

The explicit workflow:

1. Create a =DistAlgorithm= wrapper (=A=).
2. Execute concurrent operations.
3. Verify linearizability.

** DistAlgorithm wrapper

#+BEGIN_SRC java
import phd.distributed.api.A;
import phd.distributed.api.DistAlgorithm;

DistAlgorithm algorithm =
    new A("java.util.concurrent.ConcurrentLinkedQueue",
          "offer", "poll");
#+END_SRC

** Executioner (random workload)

#+BEGIN_SRC java
import phd.distributed.core.Executioner;

Executioner exec =
    new Executioner(4, 100, algorithm, "queue", "gAIsnap");

exec.taskProducers();
boolean linearizable = exec.taskVerifiers();
#+END_SRC

** Executioner (seeded workload)

#+BEGIN_SRC java
WorkloadPattern p = WorkloadPattern.readHeavy(100, 4, 0.8);
List<OperationCall> ops = p.generateOperations(algorithm, "queue");

Executioner exec =
    new Executioner(4, 100, algorithm, "queue", "gAIsnap");

exec.taskProducersSeed(ops);
boolean linearizable = exec.taskVerifiers();
#+END_SRC

* VerificationResult

Returned by =run()= or =runAsync()=.

Common methods:
- =isLinearizable()=
- =getExecutionTime()=
- =getProdExecutionTime()=
- =getVerifierExecutionTime()=
- =getStatistics().getTotalOperations()=

* AlgorithmLibrary

Helper registry for built-in implementations.

#+BEGIN_SRC java
import phd.distributed.api.AlgorithmLibrary;

AlgorithmLibrary.AlgorithmInfo info =
    AlgorithmLibrary.getInfo("ConcurrentLinkedQueue");
#+END_SRC

* Non-linearizable examples

Some distributions include intentionally broken implementations to
validate detection of violations.

#+BEGIN_SRC java
VerificationResult result = VerificationFramework
    .verify("phd.distributed.verifier.BrokenQueue")
    .withThreads(4)
    .withOperations(100)
    .withObjectType("queue")
    .withMethods("offer", "poll")
    .run();
#+END_SRC

* Recommended conventions

- Prefer the fluent API unless low-level control is required.
- Always specify =objectType= and =withMethods(...)=.
- Use workloads for realism and schedules for debugging.
- Use timeouts for large executions.